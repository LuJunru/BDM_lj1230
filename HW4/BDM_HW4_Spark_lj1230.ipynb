{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Spark\n",
    "\n",
    "In this homework, we are practicing Apache Spark.\n",
    "\n",
    "You are required to turn in this notebook as BDM\\_HW4\\_Spark\\_**NetId**.ipynb. You will be asked to complete each task using Apache Spark. Output can be printed in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (5 points)\n",
    "\n",
    "You are asked to implement Homework 3 using Spark. The description is provided below for your convenience.\n",
    "\n",
    "You are asked to implement the Social Triangle example discussed in class. In particular, given the email dataset, please list all \"reciprocal\" relationships in the company. Recall that:\n",
    "\n",
    "If A emails B and B emails A, then A and B is *reciprocal*.\n",
    "\n",
    "If A emails B but B doesn’t email A, then A and B is *directed*.\n",
    "\n",
    "**Dataset:** We will use a subset of the open [Enron Email Dataset](https://www.cs.cmu.edu/~./enron/ \"Enron Email Dataset\"), which contains approximately 10,000 simplified email headers from the Enron Corporation. You can download this dataset from NYU Classes as **enron_mails_small.csv**. The file contains 3 columns *Date*, *From*, and *To*. Their description is as follows:\n",
    "\n",
    "|Column name|Description|\n",
    "|--|--|\n",
    "|Date |The date and time of the email, in the format YYYY-MM-DD hh-mm-ss, <br />e.g. \"1998-10-30 07:43:00\" |\n",
    "|From |The sender email address, <br />e.g. \"mark.taylor@enron.com\" |\n",
    "|To | A list of recipients' email addresses separated by semicolons ';', <br />e.g. \"jennifer.fraser@enron.com;jeffrey.hodge@enron.com\" |\n",
    "\n",
    "Note that, we only care about users employed by Enron, or only relationships having email addresses that end with *'@enron.com'*.\n",
    "\n",
    "The expected output is also provided below. For each reciprocal relationship, please output a tuple consisting of two strings. The first one is always **'reciprocal'**. And the second one is a string showing the name of the two person in the following format: **'Jane Doe : John Doe'**. The names should be presented in the lexical order, i.e. there will not be a 'John Doe : Jane Doe' since 'Jane' is ordered before 'John.\n",
    "\n",
    "Though the dataset only contains email addresses, not actual names, we're assuming that the email aliases were created based on their name. For example:\n",
    "\n",
    "|Email Address|Converted Name|\n",
    "|--|--|\n",
    "|mark.taylor@enron.com|Mark Taylor|\n",
    "|alan.aronowitz@enron.com|Alan Aronowitz|\n",
    "|marc.r.cutler@enron.com|Marc R Cutler|\n",
    "|hugh@enron.com|Hugh|\n",
    "\n",
    "Please fill the code block with a series of MapReduce jobs using your own mapper and reducer functions. Be sure to include the naming convention logic into one of your mappers and/or reducers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Email_FN = \"enron_mails_small.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Date'), (1, 'From'), (2, 'To')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = sc.textFile(Email_FN)\n",
    "list(enumerate(email.first().split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark Taylor', 'Shari Stack'),\n",
       " ('Mark Taylor', 'Yao Apasu'),\n",
       " ('Mark Taylor', 'Paul Simons'),\n",
       " ('Mark Taylor', 'Justin Boyd'),\n",
       " ('Mark Taylor', 'Tana Jones')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Capitalize(full_name):\n",
    "    return ' '.join([name.capitalize() for name in full_name.split(' ')])\n",
    "\n",
    "def extractRelations(partitionID, rows):\n",
    "    if partitionID == 0:  # 去掉第一行属性名\n",
    "        next(rows)\n",
    "    import csv\n",
    "    reader = csv.reader(rows)\n",
    "    for row in reader:\n",
    "        if 'enron.com' in row[1]:\n",
    "            Sender = row[1].split('@')[0].replace('.', ' ')\n",
    "            Recipients = [recipient.split('@')[0].replace('.', ' ') for recipient in row[2].split(';') \n",
    "                          if 'enron.com' in recipient]\n",
    "            if len(Recipients) > 0:\n",
    "                for Recipient in Recipients:\n",
    "                    yield (Capitalize(Sender), Capitalize(Recipient))\n",
    "\n",
    "emailRelations = email.mapPartitionsWithIndex(extractRelations)\n",
    "emailRelations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark Haedicke',\n",
       "  {'Alan Aronowitz',\n",
       "   'Anita Fam',\n",
       "   'Barbara Gray',\n",
       "   'Bob Crane',\n",
       "   'Brad Richter',\n",
       "   'Brent Enron',\n",
       "   'Bryan Burnett',\n",
       "   'Chris Gaffney',\n",
       "   'Christi Nicolay',\n",
       "   'Christian Yoder',\n",
       "   'Cliff Baxter',\n",
       "   'Cynthia Sandherr',\n",
       "   'Dan Lyons',\n",
       "   'Darlene Forsyth',\n",
       "   'David Delainey',\n",
       "   'David Forster',\n",
       "   'David Oxley',\n",
       "   'David Roland',\n",
       "   'Deb Korkmas',\n",
       "   'Don Black',\n",
       "   'Dusty Paez',\n",
       "   'Edward Ondarza',\n",
       "   'Elisabeth Mccabe',\n",
       "   'Elizabeth Grant',\n",
       "   'Elizabeth Labanowski',\n",
       "   'Elizabeth Sager',\n",
       "   'Fiona Lavelle',\n",
       "   'G Aarti',\n",
       "   'Gareth Bahlmann',\n",
       "   'George Mcclellan',\n",
       "   'Greg Johnston',\n",
       "   'Greg Piper',\n",
       "   'Greg Whalley',\n",
       "   'Jaime Alatorre',\n",
       "   'James Fallon',\n",
       "   'James Grace',\n",
       "   'Janette Elbertson',\n",
       "   'Janice Moore',\n",
       "   'Jeffrey Hodge',\n",
       "   'Jeffrey Keeler',\n",
       "   'John Ale',\n",
       "   'John Sherriff',\n",
       "   'Joseph Hirl',\n",
       "   'Julia Murray',\n",
       "   'Julie Armstrong',\n",
       "   'Justin Boyd',\n",
       "   'Kenneth Rice',\n",
       "   'Kevin Hannon',\n",
       "   'Kristin Armstrong',\n",
       "   'Kristina Mordaunt',\n",
       "   'Lance Schuler-legal',\n",
       "   'Lisa Mellencamp',\n",
       "   'Liz Taylor',\n",
       "   'Louise Kitchen',\n",
       "   'Mark Elliott',\n",
       "   'Mark Holsworth',\n",
       "   'Mark Taylor',\n",
       "   'Martin Rosell',\n",
       "   'Michael Brown',\n",
       "   'Michael Guerriero',\n",
       "   'Michelle Cash',\n",
       "   'Misha Siegel',\n",
       "   'Monica Jordan',\n",
       "   'Nicola Beales',\n",
       "   'Nora Dobin',\n",
       "   'Paul Simons',\n",
       "   'Peter Keohane',\n",
       "   'Philippe Bibi',\n",
       "   'Randal Maffett',\n",
       "   'Richard Sanders',\n",
       "   'Rob Enron',\n",
       "   'Rob Walls',\n",
       "   'Robert Quick',\n",
       "   'Sara Davidson',\n",
       "   'Scott Sefton',\n",
       "   'Seth Hurwitz',\n",
       "   'Shari Stack',\n",
       "   'Sheila Tweed',\n",
       "   'Sheila Walton',\n",
       "   'Stacy Dickson',\n",
       "   'Steven Kean',\n",
       "   'Susan Skarness',\n",
       "   'Suzanne Adams',\n",
       "   'Sylvia Hu',\n",
       "   'Tim Belden',\n",
       "   'Tim Dorsey',\n",
       "   'Tracy Foy',\n",
       "   'Travis Mccullough',\n",
       "   'Twanda Sweet',\n",
       "   'William Krenz'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emailRelations = emailRelations.mapValues(lambda x: {x}).reduceByKey(lambda x, y: x.union(y))\n",
    "emailRelations.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark Haedicke : Mark Holsworth', 1),\n",
       " ('Greg Whalley : Mark Haedicke', 1),\n",
       " ('Lisa Mellencamp : Mark Haedicke', 1),\n",
       " ('Mark Haedicke : Monica Jordan', 1),\n",
       " ('Mark Haedicke : Tim Dorsey', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rewriteRelations(Sender, Recipients): \n",
    "    for Recipient in Recipients:\n",
    "        relation = sorted([Sender, Recipient])\n",
    "        yield (relation[0] + \" : \" + relation[1], 1)\n",
    "\n",
    "emailRelations = emailRelations.flatMap(lambda x: rewriteRelations(x[0], x[1]))\n",
    "emailRelations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reciprocal', 'Brenda Whitehead : Elizabeth Sager'),\n",
       " ('reciprocal', 'Carol Clair : Debra Perlingiere'),\n",
       " ('reciprocal', 'Carol Clair : Mark Taylor'),\n",
       " ('reciprocal', 'Carol Clair : Richard Sanders'),\n",
       " ('reciprocal', 'Carol Clair : Sara Shackleton'),\n",
       " ('reciprocal', 'Carol Clair : Tana Jones'),\n",
       " ('reciprocal', 'Debra Perlingiere : Kevin Ruscitti'),\n",
       " ('reciprocal', 'Drew Fossum : Susan Scott'),\n",
       " ('reciprocal', 'Elizabeth Sager : Janette Elbertson'),\n",
       " ('reciprocal', 'Elizabeth Sager : Mark Haedicke'),\n",
       " ('reciprocal', 'Elizabeth Sager : Mark Taylor'),\n",
       " ('reciprocal', 'Elizabeth Sager : Richard Sanders'),\n",
       " ('reciprocal', 'Eric Bass : Susan Scott'),\n",
       " ('reciprocal', 'Fletcher Sturm : Greg Whalley'),\n",
       " ('reciprocal', 'Fletcher Sturm : Sally Beck'),\n",
       " ('reciprocal', 'Gerald Nemec : Susan Scott'),\n",
       " ('reciprocal', 'Grant Masson : Vince Kaminski'),\n",
       " ('reciprocal', 'Greg Whalley : Richard Sanders'),\n",
       " ('reciprocal', 'Janette Elbertson : Mark Taylor'),\n",
       " ('reciprocal', 'Janette Elbertson : Richard Sanders'),\n",
       " ('reciprocal', 'Liz Taylor : Mark Haedicke'),\n",
       " ('reciprocal', 'Mark Haedicke : Mark Taylor'),\n",
       " ('reciprocal', 'Mark Haedicke : Michelle Cash'),\n",
       " ('reciprocal', 'Mark Haedicke : Richard Sanders'),\n",
       " ('reciprocal', 'Mark Haedicke : Twanda Sweet'),\n",
       " ('reciprocal', 'Mark Taylor : Sara Shackleton'),\n",
       " ('reciprocal', 'Mark Taylor : Tana Jones'),\n",
       " ('reciprocal', 'Michelle Cash : Twanda Sweet'),\n",
       " ('reciprocal', 'Pinnamaneni Krishnarao : Vince Kaminski'),\n",
       " ('reciprocal', 'Richard Sanders : Sara Shackleton'),\n",
       " ('reciprocal', 'Rosalee Fleming : Steven Kean'),\n",
       " ('reciprocal', 'Sara Shackleton : Tana Jones'),\n",
       " ('reciprocal', 'Shirley Crenshaw : Vince Kaminski'),\n",
       " ('reciprocal', 'Stinson Gibner : Vince Kaminski'),\n",
       " ('reciprocal', 'Vasant Shanbhogue : Vince Kaminski')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "emailRelations = emailRelations.reduceByKey(add) \\\n",
    "    .filter(lambda x: x[1] == 2).sortByKey().map(lambda x: ('reciprocal', x[0])).collect()\n",
    "print(len(emailRelations))\n",
    "emailRelations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (5 points)\n",
    "\n",
    "You are asked to implement Task 2 of Lab 5. The description is provided below for your convenience.\n",
    "\n",
    "We’ll be using two NYC open data sets: the SAT Results and the NYC High School Directory data sets. Both can be downloaded from the links below, or from online class resources.\n",
    "\n",
    "**Dataset**: *Please note that each school is uniquely identified by an DBN code, which should be found on both data sets.*\n",
    "\n",
    "**SAT_Results.csv**\n",
    "Source: https://nycopendata.socrata.com/Education/SAT-Results/f9bf-2cp4  \n",
    "Description: “The most recent school level results for New York City on the SAT. Results are available at the school level for the graduating seniors of 2012.”\n",
    "\n",
    "**DOE_High_School_Directory_2014-2015.csv**\n",
    "Source: https://data.cityofnewyork.us/Education/DOE-High-School-Directory-2014-2015/n3p6-zve2  \n",
    "Description: “Directory of NYC High Schools.”\n",
    "\n",
    "We would like to know how the Math scores vary across bus lines or subway lines serving the schools. Your task is to compute the average Math scores of all schools along each bus line and subway line. You can find the bus and subway lines serving each school in the High School Dictionary as bus and subway columns.\n",
    "\n",
    "The expected results are two lists:\n",
    "1. A list of key/value pairs: with bus line as keys, and the average Math scores as values.\n",
    "2. A list of key/value pairs: with subway line as keys, and the average Math scores as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_FN = \"SAT_Results.csv\"\n",
    "HSD_FN = \"DOE_High_School_Directory_2014-2015.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DBN='02M047', total=6400, ntakers=16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfScores = spark.read.load(SAT_FN, format='csv', header=True, inferSchema=True)\n",
    "dfScores = dfScores.select(\"DBN\", \n",
    "                           dfScores['`SAT Math Avg. Score`'].cast('int').alias('mathscore'), \n",
    "                           dfScores['Num of SAT Test Takers'].cast('int').alias('ntakers')).na.drop()\n",
    "dfScores = dfScores.select(\"DBN\", (dfScores.mathscore * dfScores.ntakers).alias(\"total\"), \"ntakers\")\n",
    "dfScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dbn='01M292', bus='B39, M14A, M14D, M15, M15-SBS, M21, M22, M9', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSchools = spark.read.load(HSD_FN, format=\"csv\", header=True, inferSchema=True)\n",
    "dfSchools = dfSchools.select(\"dbn\", \"bus\", \"subway\")\n",
    "dfSchools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dbn='01M292', bus='B39, M14A, M14D, M15, M15-SBS, M21, M22, M9', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St', DBN='01M292', total=11716, ntakers=29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResults = dfSchools.join(dfScores, dfSchools.dbn == dfScores.DBN, how=\"inner\")\n",
    "dfResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dbn='01M292', BUS='B39', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St', DBN='01M292', total=11716, ntakers=29),\n",
       " Row(dbn='01M292', BUS='M14A', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St', DBN='01M292', total=11716, ntakers=29),\n",
       " Row(dbn='01M292', BUS='M14D', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St', DBN='01M292', total=11716, ntakers=29),\n",
       " Row(dbn='01M292', BUS='M15', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St', DBN='01M292', total=11716, ntakers=29),\n",
       " Row(dbn='01M292', BUS='M15-SBS', subway='B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St', DBN='01M292', total=11716, ntakers=29)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "dfResults.withColumn(\"BUS\", f.explode(f.split(\"bus\", \", \"))).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|  BUS|avg|\n",
      "+-----+---+\n",
      "|S1115|612|\n",
      "|  M79|594|\n",
      "|  Q42|582|\n",
      "|  M22|574|\n",
      "|  Bx3|571|\n",
      "|  B52|560|\n",
      "|  B63|557|\n",
      "|  B69|548|\n",
      "|  B54|543|\n",
      "|  B25|541|\n",
      "|  M20|540|\n",
      "|   M9|539|\n",
      "|  B65|538|\n",
      "|  M86|538|\n",
      "|  B45|534|\n",
      "| Bx10|534|\n",
      "| Bx26|533|\n",
      "| B103|531|\n",
      "|  Q64|529|\n",
      "| Bx22|525|\n",
      "+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBus = dfResults.withColumn(\"BUS\", f.explode(f.split(\"bus\", \", \"))).groupBy(\"bus\").sum(\"total\", \"ntakers\")\n",
    "dfBus = dfBus.withColumn('avg', dfBus[1] / dfBus[2])\n",
    "dfBus = dfBus.select(\"BUS\", dfBus['avg'].cast('int'))\n",
    "dfBus = dfBus.sort('avg', ascending=False)\n",
    "dfBus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                 Sub|avg|\n",
      "+--------------------+---+\n",
      "|E to Chambers St ...|735|\n",
      "|4 to Bedford Park...|683|\n",
      "|     SIR to New Dorp|682|\n",
      "|Z to Jamaica Cent...|660|\n",
      "|5 to Nevins St ; ...|659|\n",
      "|N to Atlantic Ave...|659|\n",
      "|R to DeKalb Ave ;...|659|\n",
      "|   D to 145th St ; B|654|\n",
      "|        6 to 77th St|594|\n",
      "|D to Bedford Park...|593|\n",
      "|1 to 66th St - Li...|575|\n",
      "|    R to 36th St ; N|568|\n",
      "|    R to 23rd St ; B|563|\n",
      "|                   3|547|\n",
      "|Q to 14th St-Unio...|538|\n",
      "|S to Beach 105th ...|537|\n",
      "|                   A|534|\n",
      "|        R to 23rd St|533|\n",
      "|                   1|532|\n",
      "|                   Q|531|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSub = dfResults.withColumn(\"Sub\", f.explode(f.split(\"subway\", \", \"))).groupBy(\"Sub\").sum(\"total\", \"ntakers\")\n",
    "dfSub = dfSub.withColumn('avg', dfSub[1] / dfSub[2])\n",
    "dfSub = dfSub.select(\"Sub\", dfSub['avg'].cast('int'))\n",
    "dfSub = dfSub.sort('avg', ascending=False)\n",
    "dfSub.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
