{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/nfshome/lj1230/.conda/envs/myEnv/bin/python3.5'\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext('local', 'pyspark')\n",
    "\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trivials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('book.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of English Coins and Tokens, by '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd0 = sc.parallelize([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd0.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'EBook',\n",
       "  'of',\n",
       "  'English',\n",
       "  'Coins',\n",
       "  'and',\n",
       "  'Tokens,',\n",
       "  'by'],\n",
       " ['Llewellynn', 'Jewitt', 'and', 'Barclay', 'V.', 'Head'],\n",
       " []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对前三列进行操作\n",
    "\n",
    "rdd.map(lambda line: line.split()).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Project', 'Gutenberg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda line: line.split()).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 1), ('Project', 1), ('Gutenberg', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda line: line.split()).map(lambda x: (x, 1)).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CÆSAR', <pyspark.resultiterable.ResultIterable at 0x7f391ac337b8>),\n",
       " ('fellows', <pyspark.resultiterable.ResultIterable at 0x7f391ac33400>),\n",
       " ('die-sinker’s', <pyspark.resultiterable.ResultIterable at 0x7f391ac337f0>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda line: line.split()).map(lambda x: (x, 1)).groupByKey().take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CÆSAR', 1), ('fellows', 1), ('die-sinker’s', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda line: line.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2104), ('of', 1631), ('and', 1277), ('a', 875), ('or', 710)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = rdd.flatMap(lambda line: line.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n",
    "rdd1.top(5, lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAT - Task1: by RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_FN = \"SAT_Results.csv\"\n",
    "HSD_FN = \"DOE_High_School_Directory_2014-2015.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DBN,SCHOOL NAME,Num of SAT Test Takers,SAT Critical Reading Avg. Score,SAT Math Avg. Score,SAT Writing Avg. Score'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat = sc.textFile(SAT_FN)\n",
    "sat.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'DBN'),\n",
       " (1, 'SCHOOL NAME'),\n",
       " (2, 'Num of SAT Test Takers'),\n",
       " (3, 'SAT Critical Reading Avg. Score'),\n",
       " (4, 'SAT Math Avg. Score'),\n",
       " (5, 'SAT Writing Avg. Score')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(sat.first().split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('02M047', (400, 16)),\n",
       " ('21K410', (437, 475)),\n",
       " ('30Q301', (440, 98)),\n",
       " ('17K382', (374, 59)),\n",
       " ('18K637', (381, 35))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractScore(partitionID, rows):\n",
    "    if partitionID == 0:  # 去掉第一行属性名\n",
    "        next(rows)\n",
    "    import csv\n",
    "    reader = csv.reader(rows)\n",
    "    for fields in reader:\n",
    "        if fields[2] != \"s\":\n",
    "            yield (fields[0], (int(fields[4]), int(fields[2])))\n",
    "\n",
    "satScores = sat.mapPartitionsWithIndex(extractScore)\n",
    "satScores.take(5)\n",
    "# DBN, Math Avg., 人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = sc.textFile(HSD_FN).cache()\n",
    "# list(enumerate(schools.first().split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M450', 'Manhattan'),\n",
       " ('01M539', 'Manhattan'),\n",
       " ('01M696', 'Manhattan'),\n",
       " ('02M374', 'Manhattan'),\n",
       " ('02M400', 'Manhattan')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSchool(partitionID, rows):\n",
    "    if partitionID == 0:  # 去掉第一行属性名\n",
    "        next(rows)\n",
    "    import csv\n",
    "    reader = csv.reader(rows)\n",
    "    for fields in reader:\n",
    "        if len(fields) == 58 and fields[17].isdigit() and int(fields[17]) > 500:\n",
    "            yield (fields[0], fields[2])\n",
    "\n",
    "largeSchools = schools.mapPartitionsWithIndex(extractSchool)\n",
    "largeSchools.take(5)\n",
    "# DBN, 区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_sat = largeSchools.join(satScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooklyn', (374, 59)),\n",
       " ('Brooklyn', (409, 88)),\n",
       " ('Queens', (445, 68)),\n",
       " ('Queens', (449, 395)),\n",
       " ('Queens', (492, 135))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(br_sat.values().take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('17K382', ('Brooklyn', (374, 59))),\n",
       " ('28Q310', ('Queens', (445, 68))),\n",
       " ('32K545', ('Brooklyn', (409, 88))),\n",
       " ('30Q445', ('Queens', (449, 395))),\n",
       " ('30Q575', ('Queens', (492, 135)))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_sat.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooklyn', (22066, 59)),\n",
       " ('Queens', (30260, 68)),\n",
       " ('Brooklyn', (35992, 88)),\n",
       " ('Queens', (177355, 395)),\n",
       " ('Queens', (66420, 135))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_sat.values().mapValues(lambda x: (x[0] * x[1], x[1])).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooklyn', (4544126, 9322)),\n",
       " ('Manhattan', (3206992, 6228)),\n",
       " ('Queens', (5190534, 10942)),\n",
       " ('Staten Island', (1406967, 2944)),\n",
       " ('Bronx', (1619364, 3444))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_sat.values() \\\n",
    "    .mapValues(lambda x: (x[0] * x[1], x[1])) \\\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooklyn', 487.46256168204246),\n",
       " ('Manhattan', 514.9312780989081),\n",
       " ('Queens', 474.3679400475233),\n",
       " ('Staten Island', 477.9099864130435),\n",
       " ('Bronx', 470.198606271777)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largeSchools.join(satScores).values() \\\n",
    "    .mapValues(lambda x: (x[0] * x[1], x[1])) \\\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "    .mapValues(lambda x: x[0] / x[1]).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAT - Task1: by dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DBN,SCHOOL NAME,Num of SAT Test Takers,SAT Critical Reading Avg. Score,SAT Math Avg. Score,SAT Writing Avg. Score'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(DBN='02M047', total=6400, ntakers=16)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfScores = spark.read.load(SAT_FN, format='csv', header=True, inferSchema=True)\n",
    "dfScores = dfScores.select(\"DBN\", \n",
    "                           dfScores['`SAT Math Avg. Score`'].cast('int').alias('score'), \n",
    "                           dfScores['Num of SAT Test Takers'].cast('int').alias('ntakers')).na.drop()\n",
    "dfScores = dfScores.select(\"DBN\", (dfScores.score * dfScores.ntakers).alias(\"total\"), \"ntakers\")\n",
    "dfScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dbn='01M450', boro='Manhattan')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSchools = spark.read.load(HSD_FN, format=\"csv\", header=True, inferSchema=True)\n",
    "dfSchools = dfSchools.filter(dfSchools[\"total_students\"] > 500)\n",
    "dfSchools = dfSchools.select(\"dbn\", \"boro\")\n",
    "dfSchools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|         boro|               avg|\n",
      "+-------------+------------------+\n",
      "|       Queens| 474.3679400475233|\n",
      "|     Brooklyn|487.46256168204246|\n",
      "|Staten Island| 477.9099864130435|\n",
      "|    Manhattan| 514.9312780989081|\n",
      "|        Bronx|  470.198606271777|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfResults = dfSchools.join(dfScores, dfSchools.dbn == dfScores.DBN, how=\"inner\")\n",
    "dfResults = dfResults.groupBy(\"boro\").sum(\"total\", \"ntakers\")\n",
    "dfResults = dfResults.withColumn('avg', (dfResults[1] / dfResults[2]))\n",
    "dfResults = dfResults.select(\"boro\", 'avg')\n",
    "dfResults.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAT - Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
